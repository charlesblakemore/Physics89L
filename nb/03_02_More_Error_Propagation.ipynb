{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de609a45",
   "metadata": {},
   "source": [
    "# More Propagation of Errors\n",
    "\n",
    "### Goals:\n",
    "\n",
    "1. To use simulated experiments to deepen our understanding of propagation of errors.\n",
    "2. To use visual representations to further deepen our understanding of propagation of errors.\n",
    "\n",
    "### Timing\n",
    "\n",
    "1. Try to finish this notebook in 30-35 minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f8e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad4821",
   "metadata": {},
   "source": [
    "| Function Name            | What it does |\n",
    "| - | - |\n",
    "|    numpy.expand_dims     | Adds a dimension to an array, useful for expanding two 1-D arrays into a 2-D array |\n",
    "| plt.imshow               | Makes a 2D-color plot by taking the values in a 2-D array to set a color scale |\n",
    "| plt.colorbar             | Adds a key corresponding to the color scale, e.g., when using plt.imshow |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20d1d4a",
   "metadata": {},
   "source": [
    "# Visual understanding of propagation of errors\n",
    "\n",
    "### First example, how our estimate of A depends on our measurement of l\n",
    "\n",
    "We are again going to simulate 10000 measurements of the length of the desk, assuming that they come from a Gaussian distribution that is centered on the value that we measured, but that have a standard deviation of 10% of that value.  \n",
    "\n",
    "Then we are going to see what happens to the distribution of outcomes, i.e., of the measurements of the area of the desk. But we will explore it a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d6e5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8454351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deskArea(w, l, B, C):\n",
    "    return w * l * B**2 * C**2\n",
    "\n",
    "C_m = 8.\n",
    "B_m = 2.5\n",
    "l_m = 3.8\n",
    "w_m = 5.1\n",
    "A_m = deskArea(w_m, l_m, B_m, C_m)\n",
    "print(f\"Area of desk: {A_m:0.0f} cm^2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45502ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will simulate 10000 measurements with drawn from a Normal distribtuion \n",
    "# The distribtuion is centered at l_m and has standard deviation of 0.1*l_m\n",
    "l_sim = rng.normal(loc=l_m, scale=0.1*l_m, size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc1041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(l_sim, bins=np.linspace(0.6*l_m, 1.4*l_m, 81))\n",
    "plt.xlabel(\"Length of desk [in books]\")\n",
    "plt.ylabel(\"Simulated Trials [per bin]\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Measurements of desk length: {np.mean(l_sim):0.2f} ± {np.std(l_sim):0.2f} [books]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6baec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((l_sim/l_m)-1, bins=np.linspace(-0.4, 0.4, 81))\n",
    "plt.xlabel(r'Fractional Change: $\\Delta l / l$')\n",
    "plt.ylabel(\"Simulated Trials [per bin]\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fractional Change: {np.mean((l_sim/l_m)-1):0.2f} ± {np.std((l_sim/l_m)-1):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c0d48e",
   "metadata": {},
   "source": [
    "### Now, let's make a figure to show how A depends on l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4799805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a grid of value of l that covers a wide range around the value that we measured.\n",
    "l_grid = l_m*np.linspace(0.6, 1.4, 81)\n",
    "# And let's compute the Area of each value of l\n",
    "A_from_l = deskArea(w_m, l_grid, B_m, C_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858ed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we plot A version l_grid\n",
    "plt.plot(l_grid, A_from_l)\n",
    "plt.ylabel(r'Area of desk [$cm^2$]')\n",
    "plt.xlabel(r'Length of desk [units of books]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584f6767",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((l_grid/l_m)-1, (A_from_l/A_m)-1)\n",
    "plt.ylabel(r'Relative change in area $\\Delta A / A$')\n",
    "plt.xlabel(r'Relative change in length of desk $\\Delta l / l$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b540a1",
   "metadata": {},
   "source": [
    "### Questions for discussion:\n",
    "\n",
    "#### 3.1  Explain what is being shown in the two plots above.  How does this relate to the formula shown above, in particular the formula that includes the partial derivatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ab1a31",
   "metadata": {},
   "source": [
    "### Combining the sets of plots above.\n",
    "\n",
    "The first set of plots show the range of measurments we might expect for $l$ and $\\frac{\\delta}{l}$.  The second plot shows how $A$ changes if we change $l$.\n",
    "\n",
    "If we \"combine\" the two plots, we see the range of values that we might expect for $A$, given the uncertaintiy in $l$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e963989",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (axis0, axis1) = plt.subplots(2, 1, figsize=(4,6))\n",
    "\n",
    "axis0.plot((l_grid/l_m)-1, (A_from_l/A_m)-1)\n",
    "axis1.hist((l_sim/l_m)-1, bins=(l_grid/l_m)-1)\n",
    "\n",
    "axis0.set_ylabel(r'Relative change in area $\\Delta A / A$')\n",
    "axis1.set_ylabel(\"Simulated Trials [per bin]\")\n",
    "axis1.set_xlabel(r'Relative change in length of desk $\\Delta l / l$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457346cd",
   "metadata": {},
   "source": [
    "What we mean when we say that we \"combine\" the two plots, is that for each value of $\\frac{\\Delta l}{l}$ on the x-axis, the top plot tells us the resulting change $\\frac{\\Delta A}{A}$, while the bottom plot tells us how likely that value of $\\frac{\\Delta l}{l}$ is to occur.  \n",
    "\n",
    "So, we see that large changes in $l$ are less likely than small changes.  And the distribution of outcomes from our little simulation give us a sense of the scatter we would expect in $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287cc557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the area for the 10000 \"simulated\" measurements of l\n",
    "A_sim_1 = deskArea(w_m, l_sim, B_m, C_m)\n",
    "\n",
    "plt.hist(A_sim_1, bins=81)\n",
    "plt.xlabel(r'$A [{\\rm cm}^2]$')\n",
    "plt.ylabel(r'Trials [per bin]')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Area of desk: {np.mean(A_sim_1):0.2f} ± {np.std(A_sim_1):0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b544ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are going to compute the resulting relative change in A\n",
    "dA_over_A_sim_1 = (A_sim_1 - A_m)/A_m\n",
    "\n",
    "plt.hist(dA_over_A_sim_1, bins=np.linspace(-0.4, 0.4, 81))\n",
    "plt.xlabel(r'$\\Delta A / A$')\n",
    "plt.ylabel(r'Trials [per 0.02]')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fractional Change: {np.mean(dA_over_A_sim_1):0.2f} ± {np.std(dA_over_A_sim_1):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f743d43",
   "metadata": {},
   "source": [
    "## Second example: how our estimate of A depends on C\n",
    "\n",
    "Now we are going to repeat the exercise, but this time we are going to vary $C$, our estimate of the length of the card in cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796d7003",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_grid = C_m*np.linspace(0.6, 1.4, 81)\n",
    "C_sim = rng.normal(loc=C_m, scale=0.1*C_m, size=10000)\n",
    "A_from_C = deskArea(w_m, l_m, B_m, C_m*np.linspace(0.6, 1.4, 81))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df0a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((C_m*np.linspace(0.6, 1.4, 81)/C_m)-1, (A_from_C/A_m)-1)\n",
    "plt.ylabel(r'Relative area of desk $\\Delta A / A$')\n",
    "plt.xlabel(r'Relative change in length of card $\\Delta C / C$')\n",
    "plt.plot(np.linspace(-0.2,0.2,11), 2*np.linspace(-0.2,0.2,11), label=\"Tangent at zero\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc23465",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sim_2 = deskArea(w_m, l_m, B_m, C_sim)\n",
    "dA_over_A_sim_2 = (A_sim_2 - A_m)/A_m\n",
    "\n",
    "plt.hist(dA_over_A_sim_2, bins=np.linspace(-0.8, 0.8, 81))\n",
    "plt.xlabel(r'$\\Delta A / A$')\n",
    "plt.ylabel(r'Trials [per 0.05]')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fractional Change: {np.mean(dA_over_A_sim_2):0.2f} ± {np.std(dA_over_A_sim_2):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e3ee23",
   "metadata": {},
   "source": [
    "## Questions for discussion  \n",
    "\n",
    "#### 4.1 How can we interpret the two plots above?  What does it mean for our estimate of the uncertainty on $A$?  \n",
    "#### 4.2 Why does this differ from the results we got when we considered the variation in $A$ due to the variation in $l$?  \n",
    "#### 4.3 Why did we draw the tangent line on the figure a few cells up?   What does the tangent line correspond to in the equation for propagation of errors?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d6f872",
   "metadata": {},
   "source": [
    "## A special case of error propagation\n",
    "\n",
    "Recall the exercise from the previous notebook about measuring the energy flux from the sun. We're going to focus on measuring $n_\\gamma$, the number of photons measured by our photodetector in the measurement time $t$.\n",
    "\n",
    "In order to write down the distribution for $n_\\gamma$, we need to know the mean value. Let's assume the energy flux on Earth is 1000 Watts/m $^2$ (our hypothetical experimenter doesn't know this yet, though!) \n",
    "\n",
    "We'll make the approximation that all of the photons have energy 3 eV (in reality, the photon energy from the sun follows a [blackbody distribution](https://en.wikipedia.org/wiki/Black-body_radiation)) and our photodetector is 1 mm $^2$ in area. This means we expect about $10^{15}$ photons to hit our detector every second.\n",
    "\n",
    "The number of photons hitting the detector every second will therefore follow a Poisson distribution with mean $\\lambda = 1e15$ photons/second. So the probability of measuring $k$ photons in one second is given by:\n",
    "$$\n",
    "P(k|\\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1678ce7b",
   "metadata": {},
   "source": [
    "### Experiment 1\n",
    "\n",
    "Let's simulate what a single set of measurements might look like. Imagine we leave our photodetector in the sun for 10000 seconds (about 3 hours) and record the number of photons counted in each second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd8a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = rng.poisson(1e15, 10000)\n",
    "bins = np.linspace(1e15-1e8, 1e15+1e8, 100)\n",
    "plt.hist(sample1, bins)\n",
    "plt.xlabel(\"Number of photons observed\")\n",
    "plt.ylabel(\"Number of observations (per bin)\")\n",
    "\n",
    "print(f\"Sample mean : {np.mean(sample1):0.3g}\")\n",
    "print(f\"Standard dev: {np.std(sample1):0.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55073fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sample mean : {np.mean(sample1):0.3g}\")\n",
    "print(f\"Standard dev: {np.std(sample1):0.3g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9755fa5",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "##### 5.1 Do the sample mean and standard deviation match what you expect from the Poisson distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af156af",
   "metadata": {},
   "source": [
    "### Experiment 2\n",
    "\n",
    "Now imagine that we perform this measurement every day for 500 days. At the end of each day, we write down the mean and standard deviation of the dataset for that day. (We'll assume we are drawing from the same Poisson distribution every time, although in reality it will change depending on the Earth's position in its orbit.)\n",
    "\n",
    "At the end of the 500 days, we take the 500 means and plot them in a histogram. Here's what that would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create a 500x10000 array, where each row represents a single day's dataset with \n",
    "# 10,000 data points\n",
    "sample_array = rng.poisson(1e15, size=(500, 10000))\n",
    "\n",
    "# Numpy will calculate the mean and standard deviation of each of the 100 rows (axis 1) \n",
    "# and put them together into an array\n",
    "means = np.mean(sample_array, axis=1)\n",
    "print(means.shape)\n",
    "\n",
    "print(f\"Mean of the sample means:         {np.mean(means):0.3g}\")\n",
    "print(f\"Standard dev of the sample means: {np.std(means):0.3g}\")\n",
    "\n",
    "# Note that the axes are different from the previous plot!\n",
    "bins = np.linspace(1e15-1e6, 1e15+1e6, 50)\n",
    "plt.hist(means, bins)\n",
    "plt.xlabel(\"Mean number of photons\")\n",
    "plt.ylabel(\"Number of trials (per bin)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55405ced",
   "metadata": {},
   "source": [
    "### Experiment 3\n",
    "\n",
    "After 500 days, we decide that we need more data. We buy 9 more photosensors (so now we have 10) and again record for 10,000 seconds each day, giving 100,000 samples per day. We do this for another 500 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a3de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_array = rng.poisson(1e15, size=(500, 100000))\n",
    "\n",
    "means = np.mean(sample_array, axis=1)\n",
    "\n",
    "print(f\"Mean of the sample means:         {np.mean(means):0.3g}\")\n",
    "print(f\"Standard dev of the sample means: {np.std(means):0.3g}\")\n",
    "\n",
    "bins = np.linspace(1e15-1e6, 1e15+1e6, 50)\n",
    "plt.hist(means, bins)\n",
    "plt.xlabel(\"Mean number of photons\")\n",
    "plt.ylabel(\"Number of trials (per bin)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b6e45d",
   "metadata": {},
   "source": [
    "### Experiment 4\n",
    "\n",
    "Someone is cleaning out the lab next door and finds some more photosensors. Now we have 100 sensors. If we again measure for 10,000 seconds per day, that gives us 1,000,000 samples per day. We do this for another 500 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851a7ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, this will take a few seconds to run!\n",
    "sample_array = rng.poisson(1e15, size=(500, 1000000))\n",
    "\n",
    "means = np.mean(sample_array, axis=1)\n",
    "\n",
    "print(f\"Mean of the sample means:         {np.mean(means):0.3g}\")\n",
    "print(f\"Standard dev of the sample means: {np.std(means):0.3g}\")\n",
    "\n",
    "bins = np.linspace(1e15-1e6, 1e15+1e6, 50)\n",
    "plt.hist(means, bins)\n",
    "plt.xlabel(\"Mean number of photons\")\n",
    "plt.ylabel(\"Number of trials (per bin)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41814a7",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "##### 6.1 What do you notice about the shapes of the distributions for different numbers of observations taken each day? Is this what you expect?\n",
    "\n",
    "##### 6.2 What do you notice about the mean and standard deviation of each distribution? Be specific!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06decd2",
   "metadata": {},
   "source": [
    "### Comparing with theory\n",
    "\n",
    "Now let's compare the errors we see in our simulation data with what we should expect to see. To do so, we have to think about what data we are really analyzing. For experiment 1, we have a bunch of observations in a single dataset. For experiments 2, 3 and 4, we have many datasets, and what we are really plotting is the mean of each dataset.\n",
    "\n",
    "How can we calculate the standard deviation we expect for each set of mean values? We'll start with the general formula for propagation of errors:\n",
    "$$\n",
    "\\sigma_f^{2}(x_i) = \\sum_{i=1}^N \\left(\\frac{\\partial f}{\\partial x_i} \\delta x_i\\right)^2\n",
    "$$\n",
    "\n",
    "In this case, the function of interest $f$ is the *mean of the dataset*, which is given by:\n",
    "$$\n",
    "\\mu = \\frac{1}{N} \\sum_{i=1}^N x_i\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d584f9",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "##### 7.1 What are the partial derivatives $\\partial f / \\partial x_i$?\n",
    "\n",
    "##### 7.2 Plug in for the partial derivatives and simplify to show that $\\sigma_f = \\delta x_i / \\sqrt{N}$\n",
    "\n",
    "Hint: Keep in mind that we are drawing from the same distribution every time we make a measurement. What does this tell you about the values of $\\delta x_i$?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff41ff",
   "metadata": {},
   "source": [
    "### Surprise! We've just derived the formula for the standard error on the mean.\n",
    "\n",
    "##### 7.3 Does this exercise contribute to your understanding of the standard error? If so, how? How does the standard error on the mean differ from the individual standard deviations of each measurement?\n",
    "\n",
    "##### 7.4 Plug in numbers to show that the means and standard errors that we found in the simulations above agree with the formula $\\sigma_f = \\delta x_i / \\sqrt{N}$. Please show your work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4630cff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
