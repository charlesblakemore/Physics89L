{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency analysis.\n",
    "\n",
    "### Goals:\n",
    "\n",
    "1. To gain an intuitive understanding of frequency analysis, by applying frequency analysis to some audio clips.\n",
    "2. To deepen that understanding by applying frequency-based filters and by applying frequency analysis to simplified waveforms.\n",
    "\n",
    "### Timing\n",
    "\n",
    "1. Try to finish this notebook in 30-35 minutes.\n",
    "\n",
    "### Question and Answer Template\n",
    "\n",
    "You can go to the link below, and do \"file\" -> \"make a copy\" to make yourself a google doc that you can use to fill in the answers to the question in this weeks notebooks.\n",
    "\n",
    "https://docs.google.com/document/d/1ZOuiN04bB3rT4KpZA-wxVbDGfIJkM1UwuXGcIUJbtmM/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.signal import square\n",
    "from scipy.io.wavfile import read, write\n",
    "from IPython.display import Audio, Image\n",
    "from scipy.fftpack import fft\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note of the functions used in this week's notebooks.\n",
    "\n",
    "This week we are going to be using a number of advanced functions for signal processing. Rather than try to explain the function, we think it is more useful to focus on the figures and the associated explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Time Series Data \n",
    "\n",
    "In a physical experiment, oftentimes the data we are collecting is acquired over time. One simple way to visualize such a dataset is to just plot each data point as a function of time, which is exactly what we did in weeks 4 and 5 with the Vela Pulsar data that the Fermi Gamma-ray Space Telescope has been collecting for 13 years. We saw that this representation of the data was useful for quantifying the correlation between gamma-ray fluctuations and time, and we even fit a model that described how the data changed as time went on. \n",
    "\n",
    "In this next set of notebooks, we are going to explore a complementary visualization of the data that decomposes a time-based dataset, or time series signal, into the various frequency components that make up the signal. Although this might sound confusing and abstract at first, one intuitive way to understand this concept is by applying these techniques to music!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will begin by downloading various audio files that we have provided for you. Please select one music file (whichever one you want, the choice is not important for the rest of the lab) and play it to make sure you can hear the music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## UN-COMMENT ONE OF THE AUDIO FILES BELOW BY REMOVING THE # SYMBOL\n",
    "\n",
    "wav = os.path.join('audio_files','ImperialMarch60.wav')\n",
    "#wav = os.path.join('audio_files','Fanfare60.wav')\n",
    "#wav = os.path.join('audio_files','CantinaBand60.wav')\n",
    "#wav = os.path.join('audio_files','PinkPanther60.wav')\n",
    "\n",
    "\n",
    "sr, samps = read(wav)\n",
    "Audio(samps, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have listened to the music, we will visualize the audio as a function of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples_per_second = sr\n",
    "total_samples = len(samps)\n",
    "time_seconds = total_samples / samples_per_second\n",
    "time_vector = np.linspace(0, time_seconds, total_samples)\n",
    "\n",
    "plt.plot(time_vector, samps)\n",
    "plt.title(\"Audio file in the time domain\");\n",
    "plt.xlabel('time (sec)');\n",
    "plt.ylabel('amplitude');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this representation, the amplitude of the audio signal relates to the volume of the sound being heard. Sound is fundamentally made up of acoustic waves that create vibrations in a medium, and in a sound recording device (a microphone) these vibrations are collected and transformed into equivalent electronic waves that can be processed, edited, and eventually converted back into audio through a speaker system. Because of the natural interpretation of sound as being made up of waves, it makes sense for us to represent the audio in terms of the frequency components that make up the sound, which you can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSpectrum(y,Fs):\n",
    " \n",
    " #Plots a Single-Sided, normalized frequency space representation\n",
    " #of a time series y with sampling rate Fs\n",
    " \n",
    "    N = len(y) # length of the signal\n",
    "    k = np.arange(N)\n",
    "    T = N/Fs   # time spacing between samples\n",
    "    frq = k/T # two sided frequency range\n",
    "    frq = frq[range(N//2)] # one side frequency range\n",
    "\n",
    "    Y = fft(y)/N # fft computing and normalization\n",
    "    Y = Y[range(N//2)]\n",
    "    \n",
    "    plt.plot(frq,abs(Y)) # plotting the spectrum\n",
    "    plt.xlabel('Freq (Hz)')\n",
    "    plt.ylabel('|Y(freq)|')\n",
    "    plt.title('Frequency Domain Representation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTimeAndSpectrum(y,Fs):\n",
    " \n",
    " #Plots a Single-Sided, normalized frequency space representation\n",
    " #of a time series y with sampling rate Fs alongside its time series\n",
    " \n",
    "    N = len(y) # length of the signal\n",
    "    k = np.arange(N)\n",
    "    T = N/Fs   # time spacing between samples\n",
    "    frq = k/T # two sided frequency range\n",
    "    frq = frq[range(N//2)] # one side frequency range\n",
    "\n",
    "    Y = fft(y)/(N/2) # fft computing and normalization\n",
    "    Y = Y[range(N//2)]\n",
    " \n",
    "    \n",
    "    time_vector = np.linspace(0, 1, N)\n",
    "\n",
    "    plt.figure();\n",
    "    plt.title('Time Domain Representation')\n",
    "    plt.plot(time_vector, y);\n",
    "    plt.xlabel('time (normalized)')\n",
    "    plt.ylabel('amplitude')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure();\n",
    "    plt.title('Frequency Domain Representation')\n",
    "    plt.plot(frq,abs(Y)) # plotting the spectrum\n",
    "    plt.xlabel('Freq (Hz)')\n",
    "    plt.ylabel('|Y(freq)|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotSpectrum(samps, sr)\n",
    "plt.xlim([2, 2e4])\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for Discussion\n",
    "\n",
    "#### 1.1 What features of the music can be understood by the time domain plot? How well can these features be determined by just listening to the music?\n",
    "\n",
    "#### 1.2 What features of the music can be understood by the frequency domain plot? How well can these features be determined by just listening to the music? For example, can you associate specific sounds or instruments in the music with peaks in the frequency space plot?\n",
    "\n",
    "#### 1.3 Now choose a different music sample and compare/contrast the frequency space representation of the music. Does this make sense with what you hear from both files?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Fourier Transform\n",
    "\n",
    "The frequency space plot above was created using a widely applicable mathematical tool known as the Fourier Transform. A \"transform\" in math converts a function of one variable into a function of a different variable, and in particular the Fourier transform gives us our original function in terms of its various frequency components. Information about the distribution and magnitude of frequencies that make up a signal is often way more useful for both studying and processing the data you have collected.\n",
    "\n",
    "You will explore the mathematical formalism of this method in future classes (probably multiple times), but for this lab, we want to develop an intuition for how time series signals look in frequency space, starting with simple examples.\n",
    "\n",
    "## A Note On Finite Sampling Rates (optional reading)\n",
    "\n",
    "Because a truly continuous function would require infinitely many points to describe it, any digital waveform processing must rely on sampling the signal at a finite set of points such that we don't lose any information about the signal we are reading. This can be accomplished with a sampling rate (samples per second) higher than twice the largest frequency present in the signal, a result in signal processing theory known as Nyquist's theorem. When a signal is under-sampled (the sampling rate is lower than twice the signal frequency), we end up capturing a wave that is different from the original one, an effect known as aliasing. The figure below demonstrates this effect, where the sampled points (the black dots) determine the measured signal and the under-sampled signal leads to the incorrect wave. Because humans can hear in a frequency band (range) from about 20-20,000 Hz, a typical sampling rate for music is 44.1 kHz.\n",
    "\n",
    "Another consequence of converting a continuous signal to a digital format made up finite samples is that a discrete version of the Fourier Transform has to be applied. This method converts a sequence of time series sampled data into an equally sized sequence of frequency space data. An efficient algorithm for computing the Discrete Fourier Transform, known as the Fast Fourier Transform (FFT), is what we have used for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=os.path.join('figures', 'aliasing.PNG')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Sine Wave\n",
    "\n",
    "We can see from the plot below that a wave with a single frequency has a very simple frequency space representation as a very narrow peak at that frequency. In real life, you could interpret this kind of signal as a pure tone, like one you would create when playing a single note on a piano. Note that while theoretically the peak in frequency space should be infinitely narrow, there is always some broadening of this peak due to the finite sampling rates mentioned above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Fs = 200  # sampling rate\n",
    "t = np.arange(0,1,1.0/Fs)  # time vector\n",
    "\n",
    "f = 10  # frequency of the signal\n",
    "sine = np.sin(2*np.pi*f*t)\n",
    "\n",
    "plotTimeAndSpectrum(sine, Fs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Sine Waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Fs = 500  # sampling rate\n",
    "t = np.arange(0,1,1.0/Fs)  # time vector\n",
    "\n",
    "f1 = 5  # frequency of the signal\n",
    "sine1 = np.sin(2*np.pi*f1*t)\n",
    "\n",
    "f2 = 25\n",
    "sine2 = 0.5*np.sin(2*np.pi*f2*t)\n",
    "\n",
    "f3 = 50\n",
    "sine3 = 0.25*np.sin(2*np.pi*f3*t)\n",
    "\n",
    "sig = sine1+sine2+sine3\n",
    "\n",
    "plotTimeAndSpectrum(sig, Fs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 1000  # sampling rate\n",
    "t = np.arange(0,1,1.0/Fs)  # time vector\n",
    "\n",
    "rand_sig = np.random.rand(len(t))\n",
    "rand_sig = rand_sig - np.mean(rand_sig)\n",
    "plotTimeAndSpectrum(rand_sig, Fs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Square Wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 1000  # sampling rate\n",
    "t = np.arange(0,1,1.0/Fs) # time vector\n",
    "\n",
    "f = 25\n",
    "square_wave = square(2 * np.pi * f * t)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(t, square_wave)\n",
    "plt.title('Time Domain Representation')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plotSpectrum(square_wave, Fs)\n",
    "plt.xticks(np.linspace(0, Fs/2, 11))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for Discussion\n",
    "\n",
    "#### 2.1 For each of the three signals above (not including the single sine wave): Was one representation of the data more informative than the other? Is there information that you can understand from one representation that you can't from the other?\n",
    "\n",
    "#### 2.2 For the square wave signal, how do you think the frequency component with the largest magnitude relates to the frequency of the square wave as a whole? \n",
    "\n",
    "#### 2.3 Given your answer to 2.2, how would you then interpret the higher frequency components with smaller amplitude and their contribution to the square wave shape?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Signal Filtering\n",
    "\n",
    "Now we will apply our understanding of frequency space and perform signal manipulation that suppresses certain frequencies while not disturbing others. This kind of signal filtering is useful, for example, when the signal of interest is separated from the noise in the data in frequency space, and so a suitable filter can remove the noise without removing the important signal. \n",
    "\n",
    "Two kinds of filters we will consider are \"low-pass\" and \"high-pass\" filters, which, like the names suggest, allow signals below or above a certain cut-off frequency to pass through while suppressing all other frequencies. An example of a low-pass filter with a cut-off frequency of 50 Hz is plotted below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f_cutoff = 50;\n",
    "b, a = signal.butter(1, f_cutoff, 'low', analog=True)\n",
    "w, h = signal.freqs(b, a)\n",
    "plt.semilogx(w, abs(h))\n",
    "plt.title('Low-Pass filter frequency response')\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('Amplitude retention')\n",
    "plt.margins(0, 0.1)\n",
    "plt.grid(which='both', axis='both')\n",
    "plt.axvline(f_cutoff, color='green') # cutoff frequency\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this low-pass filter performs on the square wave we studied above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f_cutoff = 50\n",
    "\n",
    "# change this variable from \"lp\" to \"hp\" to turn this into a high-pass filter\n",
    "filter_type = 'lp'\n",
    "\n",
    "sos = signal.butter(1, f_cutoff, filter_type, fs=1000, output='sos')\n",
    "\n",
    "filtered_sig = signal.sosfilt(sos, square_wave)\n",
    "\n",
    "plotTimeAndSpectrum(filtered_sig, 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question for Discussion\n",
    "\n",
    "#### 3.1 How does the low-pass-filtered square wave differ from the unfiltered wave in the time domain and the frequency domain? If this changes your understanding of the frequency space form of the square wave, make sure to go back and re-answer questions 2.2/2.3. Hint: if this question isn't making sense, try switching the filter type in the cell above to a high-pass filter and see what remains of the square wave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will return to our music files, and see how high-pass filtering changes how the music sounds, as well as how it changes the frequency space representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vary the cutoff frequency below for question 4.2\n",
    "f_cutoff = 2000\n",
    "\n",
    "sos = signal.butter(4, f_cutoff, 'hp', fs=sr, output='sos')\n",
    "\n",
    "filtered_sig = signal.sosfilt(sos, samps)\n",
    "\n",
    "plotTimeAndSpectrum(filtered_sig, sr)\n",
    "plt.xlim([2, 2e4])\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filtered_sig, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for Discussion\n",
    "\n",
    "#### 4.1 Is the effect of the filter more clear in the time domain or the frequency domain?\n",
    "\n",
    "#### 4.2 How did the sound of the music change after filtering? Does this change agree with your intuition? Try varying the cut-off frequency in the code above to see when this effect becomes more or less significant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
