{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf5dee8",
   "metadata": {},
   "source": [
    "# Gaussian distributions: how to recognize them, and where they come from\n",
    "\n",
    "### Goals:\n",
    "\n",
    "1. To understand the basic properties of a Gaussian distribution (a.k.a. \"Normal Distribution\", a.k.a. \"Bell Curve\").\n",
    "2. To understand the parameters of the Gaussian distribution.\n",
    "3. To get an intuitive sense of why Gaussian distributions are so common in science, and what sorts of process might give rise to Gaussian distributions.\n",
    "4. To understand how and why Gaussian distributions are used to express statistical significance, and how to convert between Gaussian \"sigma\" and p-value.\n",
    "\n",
    "### Timing\n",
    "\n",
    "1. Try to finish this notebook in 35 minutes.\n",
    "\n",
    "### Question and Answer Template\n",
    "\n",
    "You can go to the link below, and do \"file\" -> \"make a copy\" to make yourself a google doc that you can use to fill in the answers to the question in this weeks notebooks.\n",
    "\n",
    "https://docs.google.com/document/d/1PRAfG7BCHlPPmUgr68LhfN-57YYKz34O4-NEn_hKcUk/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9093ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b216aee",
   "metadata": {},
   "source": [
    "### New functions we will use in this module\n",
    "\n",
    "| Function Name            | What it does |\n",
    "| - | - |\n",
    "|    rng.poisson           | generates a random integer from a \"Poisson\" distribution |\n",
    "|    scipy.stats.norm      | Interact with a Gaussian distribution |\n",
    "|    plt.annotate          | Add text to a plot |  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f736990",
   "metadata": {},
   "source": [
    "# Gaussian distribution, aka Normal Distribution, aka Bell Curve\n",
    "\n",
    "A Gaussian distribution is a distribution defined by:\n",
    "\n",
    "$G(x | \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "Where the notation $G(x | \\mu, \\sigma)$ means that:\n",
    "\n",
    "The function $G$ depends on $x$, $\\mu$ and $\\sigma$, but typically we provide $\\mu$ and $\\sigma$ to define a specific curve as a function of $x$.\n",
    "\n",
    "$x$ is what we sometimes call the \"independent variable\", while $\\mu$ and $\\sigma$ are sometimes called \"parameters\".  Basically, each set of values of $\\mu$ and $\\sigma$ defines a different curve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56872525",
   "metadata": {},
   "source": [
    "If we take $\\mu = 0$ and $\\sigma = 1$ then the formula simplifies somewhat:\n",
    "\n",
    "$G(x | \\mu=0, \\sigma=1) = \\frac{1}{1\\sqrt{2\\pi}}e^{-\\frac{(x - 0)^2}{2*1^2}} = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{x^2}{2}}$\n",
    "\n",
    "This is referred to as the \"standard normal distribution\" or \"unit-Gaussian\" (more on this later). \n",
    "\n",
    "Let's write a function to compute a Gaussian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b3a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu=0., sigma=1.):\n",
    "    return np.exp(-((x-mu)/(np.sqrt(2)*sigma))**2)/(sigma*np.sqrt(2*np.pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444661e7",
   "metadata": {},
   "source": [
    "Let's plot that.  We are going to use the equation I wrote out above, and also the 'scipy.stats.norm' function to do it and then compare the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7d97c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.linspace(-6, 6, 601)\n",
    "y_vals_check = gaussian(x_vals, mu=0, sigma=1)\n",
    "# Note that the arguments have different names, and the function is called slightly differently\n",
    "# i.e., you specify the parameters in the call to norm() and then the independent variable in the call to pdf()\n",
    "y_vals = stats.norm(loc=0, scale=1).pdf(x_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aebd56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_vals, y_vals, label=\"scipy.stats version\")\n",
    "plt.plot(x_vals, y_vals_check, label=\"function\")\n",
    "plt.legend()\n",
    "plt.title(\"My first Gaussian\")\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$G(x | \\mu=0, \\sigma=1)$')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d75bd9d2",
   "metadata": {},
   "source": [
    "### Properties of a Gaussian\n",
    "\n",
    "Some properties we can infer just by examining the formula:\n",
    "\n",
    "1. Since $\\frac{(x-\\mu)^2}{2\\sigma^2}$ is always postive, and there is a minus sign in front of it, the term in the exponent is always zero or negative.  That means the maximum is when that term is zero, i.e., when $x = \\mu$. Thus, $\\mu$ gives the location of the peak of the distribution.  \n",
    "2. Since the term in the exponent, $\\frac{(x - \\mu)^2}{2\\sigma^2}$, is symmetric about $\\mu$, the Gaussian distribution is symmetric about $\\mu$, i.e., $G(x = \\mu + a | \\mu, \\sigma) = G(x = \\mu - a | \\mu, \\sigma)$\n",
    "3. The distribution is always positive, i.e., $e^{-x} > 0$ for all x.\n",
    "4. The distribution goes towards zero pretty quickly where $(x - \\mu)^2$ is bigger than $\\sigma$.  \n",
    "\n",
    "And we can confirm those by looking at the plot. \n",
    "\n",
    "One thing to note:  the peak of the distribution is at $\\frac{1}{\\sqrt{2\\pi}} \\sim 0.4$.  This is to ensure that the integral of the distribution is 1, i.e.,\n",
    "\n",
    "$\\int_{-\\infty}^{\\infty} G(x | \\mu, \\sigma) = 1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dded579",
   "metadata": {},
   "source": [
    "### What happens when we change the parameters?\n",
    "\n",
    "First, lets plot a series of Gaussians with different values of $\\mu$.\n",
    "\n",
    "Then we will plot a series of Gaussians with different values of $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb449e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mu in np.linspace(-3, 3, 7):\n",
    "    plt.plot(x_vals, gaussian(x_vals, mu=mu), label=rf\"$\\mu = {mu:0.1f}$\")\n",
    "\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$G(x | \\mu, \\sigma=1)$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sigma in np.linspace(0.4, 1.6, 7):\n",
    "    plt.plot(x_vals, gaussian(x_vals, sigma=sigma), label=rf\"$\\sigma = {sigma:0.1f}$\")\n",
    "\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$G(x | \\mu=0, \\sigma)$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0851fb",
   "metadata": {},
   "source": [
    "### Questions for discussion\n",
    "\n",
    "#### 1.1 Why do all the Gaussians in the first example have the same height, while the ones in the second example do not?  Answer both in terms of the formula, and in plain english. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5112a6d3",
   "metadata": {},
   "source": [
    "### A comment on nomenclature / jargon:\n",
    "\n",
    "We can always shift and rescale a Gaussian by setting $x' = \\frac{x - \\mu}{\\sigma}$ so that the quantity in the exponent becomes \n",
    "\n",
    "$e^{-(\\frac{x'}{2})^2}$\n",
    "\n",
    "In practical terms, this means that if we have some quantity that we think is described by a Gaussian, we can subtract off the mean and divide by the standard deviation and it will now be described by a so-called \"unit-Gaussian\" i.e., a Gaussian with $\\mu =0$ and $\\sigma = 1$.\n",
    "\n",
    "Because of this fact, there is a pretty standard jargon to refer to the x-axis of a Gaussian as though it had units of $\\sigma$.  I.e., we say things like \"a $3 \\sigma$ outlier\" all the time.  This would mean that, for that data point, $x - \\mu = 3 \\sigma$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c677a",
   "metadata": {},
   "source": [
    "# Why a Gaussian?\n",
    "\n",
    "We are learning about Gaussians because they occur all the time in nature. \n",
    "\n",
    "In short, a Gaussian distribution is what you get when a lot of random effects add up together, no matter what process causes these random effects, or, in statistical terms, no matter what probability distribution the individual samples are drawn from. This means that even if the individual samples don't follow a Gaussian distribution, the sum of those samples will tend to look more and more like a Gaussian distribution as the sample size gets larger. This is known as the central limit theorem. The central limit theorem is important because it allows us to make statistical inferences about a population based on a sample of data, even if we don't know much about the underlying population's distribution.\n",
    "\n",
    "We are going to illustrate this with 2 different examples, where the individual samples are generated with a uniform and a Poisson distribution, respectively, and show that we get very Gaussian-looking distributions.\n",
    "\n",
    "1.  We are going to generate 10000 sets of 12 random numbers from a uniform distribution between 0 and 1, i.e., there's no preference for certain numbers between 0 and 1, and add each set together. This will give us 10000 numbers between 0 and 12, and we will see that their distribution looks a lot like a Gaussian with $\\mu = 6$ and $\\sigma = 1$. \n",
    "\n",
    "2.  We are going to generate 10000 trials of an experiment, where on average, we expect to see 100 \"events\" in each trial. \"Events\" could be pretty much anything that you can count: nuclear decays, detections of distant supernovae, cars passing through an intersection, etc. The number of events in each individual trial therefore follows the Poisson distribution. This will give us 10000 numbers that are distributed very close to a Gaussian with $\\mu = 100$ and $\\sigma = 10$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f4bf91",
   "metadata": {},
   "source": [
    "#### A Gaussian as the sum of 12 uniformly distributed numbers between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813dbe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ed5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line tells numpy to generate 120000 random numbers betweeen 0 and 1\n",
    "# split into 10000 groups of 12 \n",
    "randomNumbers = rng.uniform(size=(10000, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18d5050",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inspect the distribution of one set\n",
    "plt.hist(randomNumbers[0],bins=np.linspace(0,1,20))\n",
    "plt.xlabel(r'Value')\n",
    "plt.ylabel(r'Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62491eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line takes the sum of each group of 12, giving us a total of 10000 numbers\n",
    "sums = np.sum(randomNumbers, axis=1)\n",
    "print(\"Some numbers are \", sums)\n",
    "print(f\"And we have {sums.size} numbers total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804ea161",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = np.linspace(0,12,121)\n",
    "\n",
    "# Note: The Gaussian is defined so that it integrates to 1.  But:\n",
    "#  1) We generated 10000 numbers\n",
    "#  2) Our histogram bins are 0.1 units wide.  \n",
    "# So, to get the height of the curve to match the histogram we need to multiply by a prefactor of 10000 * 0.1\n",
    "\n",
    "plt.hist(sums, bins=xvals)\n",
    "plt.axvline(x=np.mean(sums), ls='--', c='k')\n",
    "plt.axvline(x=np.mean(sums)+np.std(sums), ls=':', c='k')\n",
    "plt.axvline(x=np.mean(sums)-np.std(sums), ls=':', c='k')\n",
    "\n",
    "prefactor = 10000 * 0.1\n",
    "myGauss = prefactor*stats.norm(loc=6, scale=1).pdf(xvals)\n",
    "plt.plot(xvals, myGauss, label=r'$G(x | \\mu=6, \\sigma=1)$')\n",
    "\n",
    "plt.xlabel(r'sum of 12 random numbers [a.u.]')\n",
    "plt.ylabel(r'Counts [per 0.1 a.u.]')\n",
    "plt.legend()\n",
    "plt.annotate(f\"mean = {np.mean(sums):0.2f}\", (10, 320))\n",
    "plt.annotate(f\"std = {np.std(sums):0.2f}\", (10, 300))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a11ae2",
   "metadata": {},
   "source": [
    "### Questions for discussion\n",
    "\n",
    "#### 2.1 Notice in the figure above that the $\\mu$ and $\\sigma$ of the Gaussian that we chose are very close to the mean and standard deviation of the distribution of sums.  How do you think the parameters of the Gaussian should change if we added together more numbers, say 24 numbers instead of 12 numbers? (Hint: The variance of a uniform distribution from $a$ to $b$ is $\\frac{(b-a)^2}{12}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faca6b6",
   "metadata": {},
   "source": [
    "#### A Gaussian as the distribution of a (large) number of random occurences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de7dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line tells numpy to simulate 10000 trials of an experiment \n",
    "#  where on average we expect to see 100 \"events\" in each trial\n",
    "# \"Events\" could be pretty much anything that you can count: \n",
    "# nuclear decays, detections of distant supernovae, cars passing through an intersection.  \n",
    "nEvts = rng.poisson(lam=100, size=10000)\n",
    "# Then this line tells numpy to count how many numbers in each group of 1000 are less that 0.1\n",
    "print(f\"Some numbers are {nEvts}\")\n",
    "print(f\"And we have {nEvts.size} numbers total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3249f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = np.linspace(50,150,101)\n",
    "\n",
    "plt.hist(nEvts, bins=xvals)\n",
    "plt.axvline(x=np.mean(nEvts), ls='--', c='k')\n",
    "plt.axvline(x=np.mean(nEvts)+np.std(nEvts), ls=':', c='k')\n",
    "plt.axvline(x=np.mean(nEvts)-np.std(nEvts), ls=':', c='k')\n",
    "\n",
    "# Note.  The Gaussian is defined so that it integrates to 1.  But:\n",
    "#  1) We generated 10000 numbers\n",
    "#  2) Our histogram bins are 1.0 units wide.  \n",
    "# So, to get the height of the curve to match the histogram we need to multiply by 10000\n",
    "myGauss = 10000*stats.norm(loc=100, scale=10).pdf(xvals)\n",
    "plt.xlabel(r'$n_{\\rm evt}$')\n",
    "plt.ylabel(r'Counts [per number]')\n",
    "plt.plot(xvals, myGauss, label=r'$G(x, \\mu=100, \\sigma=10)$')\n",
    "plt.legend()\n",
    "\n",
    "plt.annotate(f\"mean = {np.mean(nEvts):0.2f}\", (130, 330))\n",
    "plt.annotate(f\"std = {np.std(nEvts):0.2f}\", (130, 300))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8708451",
   "metadata": {},
   "source": [
    "### Questions for discussion\n",
    "\n",
    "#### 2.2 How do you think the distribution would look if we set a lower average number of events per trial (let's say 3)? Feel free to test it out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885d1cb3",
   "metadata": {},
   "source": [
    "# P-values and statistical significance\n",
    "\n",
    "### You want to pay very close attention here.\n",
    "\n",
    "One type of question that arises all the time in scientific data analysis is something along the lines of: \"Are we seeing a random fluctuation, or is this a real signal?\"  One of the ways in which we answer that question is by rephrasing it as: \"How likely (or unlikely) is it that truly random data could have fluctuated in such a way as to give us a result at least this suprising?\"   \n",
    "\n",
    "That is the concept of a p-value.  In words it is the probabilitly, given random data with no signal, to see an outlier at least as big as what we observed.\n",
    "\n",
    "If we believe that our data are distributed as a Gaussian, then mathematically, the probability of seeing an outlier equal to or larger than $x_0$ is\n",
    "\n",
    "$p(x_0) = 1 - \\int_{-\\infty}^{x_0} G(x | \\mu, \\sigma) dx$\n",
    "\n",
    "The scipy.stats package calls this quantity 'sf' for 'survival fraction'.\n",
    "\n",
    "Let's have a look at it, for a \"Unit Gaussian\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9804685",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vals = stats.norm(loc=0, scale=1).pdf(x_vals)\n",
    "y_sf = stats.norm(loc=0, scale=1).sf(x_vals)\n",
    "\n",
    "plt.plot(x_vals, y_vals, label=\"Gaussian\")\n",
    "plt.plot(x_vals, y_sf, label=\"Survival Fraction\")\n",
    "plt.legend()\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$G(x | \\mu=0, \\sigma=1)$')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3413da16",
   "metadata": {},
   "source": [
    "The survival fraction (a.k.a. the p-value) goes to zero pretty quickly once you get out past about 1-2 times the standard deviation.  That is just saying that there isn't really a lot of stuff out in the tails of the Gaussian distribution.\n",
    "\n",
    "Let's switch to plotting the y-axis on a log scale to see what is going on out there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f61091",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.yscale(\"log\")\n",
    "#plt.plot(x_vals, y_vals, label=\"Gaussian\")\n",
    "plt.plot(x_vals, y_sf, label=\"Survival Fraction\")\n",
    "plt.legend()\n",
    "plt.xlabel(r'$\\frac{x - \\mu}{\\sigma}$')\n",
    "plt.ylabel(r'$p(x, \\mu=0, \\sigma=1)$')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cab3c81",
   "metadata": {},
   "source": [
    "That plot show us that values around less than about $2 \\sigma$ (note the use of the jargon in defining value in terms of $\\sigma$) are pretty common, but once we get past $2 \\sigma$, the odds of seeing a value out there if the data are truly random get to be very small very quickly.  The odds of seeing a fluctuation at the $6 \\sigma$ level at about 1 in 10 to the 9th, i.e., 1 in a billion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2678a92e",
   "metadata": {},
   "source": [
    "### Questions for discussion\n",
    "\n",
    "#### 3.1 Different fields have different conventions for what constitutes a \"statistically significant\" result.  In many fields a p-value of $< 0.05$ is considered significant.  In other fields, the threshold is $5 \\sigma$.  How much more unlikely is a $5 \\sigma$ fluctuation than one with a p-value of 0.05?   Why do you think that different fields might use such different conventions?  (It is ok to guess...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
